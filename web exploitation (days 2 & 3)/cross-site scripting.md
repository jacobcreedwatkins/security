# HTTP

Two main types:
1. Request
2. Reply

##### HTTP Methods

- GET 		:	*requesting or retrieving data*
- HEAD 
- POST 		:	*sending information i.e. login credentials*

*Example:*
GET / HTTP/1.1
- GET = HTTP Method to Request/Retrieve
- / = www.google.com/
- HTTP/1.1 = HTTP Version being used

##### HTTP Status Codes

[list of codes](https://tools.ietf.org/html/rfc2616)

- 1xx = Informational Response
- 2xx = Successful
- 3xx = Redirection
- 4xx = Client Error
- 5xx = Server Error

### HTTP Developer Console

1. Open a web page in firefox
2. Right click -> `view page source`
3. press `f12`
 
#### Console Tab

`document.location;`
`document.cookie;`
`function();`		*can run existing functions on the website*
<script>
function myFunction() {
document.getElementById("demo").innerHTML = "Paragraph changed.";} </script>
#### Network Tab

##### GET methods
- Headers	:	Shows information about nature of client-server relationship
- User Agent	:	Gives user-agent information, useful for forensics

right click -> `copy as cURL`	:	shows CLI syntax for sending that specific GET request
- example: `curl 'https://quotes.toscrape.com/' -H 'User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:95.0) Gecko/20100101 Firefox/95.0' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8' -H 'Accept-Language: en-US,en;q=0.5' -H 'Accept-Encoding: gzip, deflate, br' -H 'Referer: https://www.google.com/' -H 'Connection: keep-alive' -H 'Upgrade-Insecure-Requests: 1' -H 'Sec-Fetch-Dest: document' -H 'Sec-Fetch-Mode: navigate' -H 'Sec-Fetch-Site: cross-site'`

# WGET & CURL

#### WGET 
`wget -r -l2 -P /tmp ftp://ftpserver/`

^	`-r` recurisve, `-l2` 2 layers deep, `-P /tmp` saves to tmp directory
- Don't rely on using WGET as a crutch

#### CURL 
`curl -o example.html http://www.reddit.com`

# JAVASCRIPT

- JavaScript runs on the client's machine
- Coded as `.js` files or in line with html

 ## JavaScript interactive

- below reference formatting will suck in `.md` format

```java
<script>
function changeText() {
  x = document.getElementById("mySelect");
  x.options[x.selectedIndex].text = "Melon";
}
Select your favorite fruit:
<select id="mySelect">
  <option>Apple</option>
  <option>Orange</option>
  <option>Pineapple</option>
  <option>Banana</option>
<input type="button" onclick="changeText()" value="Set text of selected option">`
```
# WEB ENUMERATION STEPS
	
- The goal of web enumeration is to find out the existing webpages and webdirectories
	
1. Host Discovery (ping sweep)
2. Host Enumeration (port scan)
	`nmap -Pn -T5 x.x.x.x -p-`
	
3. Service enumeration (-sV|banner.nse)
	`nmap -Pn -T5 x.x.x.x -sV -p <ports>`
	`nmap -Pn -T5 x.x.x.x --script=banner.nse -p <ports>`
	
4. Web Enumeration
	`nmap -Pn -T5 -sT -p 80 --script http-enum.nse x.x.x.x`
	`nmap -Pn -T5 -sT -p 80 --script http-sql-injection.nse x.x.x.x`
	`nmap -Pn -T5 -sT -p 80 --script http-robots.txt.nse x.x.x.x`
	
	^ robots.txt finds webpages you can navigate to outside of the normal means
	
	So what actually is the robots.txt file?
	- Robots.txt tells webcrawlers what **can** and **cannot** be indexed
	
Example: ((syntax will suck in .md format))
```
	User-agent: *
	Allow: /uploads
	Allow: /chat
	Allow: /cmdinjection
	Allow: /java
	Allow: /path
	Allow: /webexampe
	Disallow: /cross
	Disallow: /
``` 

	User-agent: Googlebot
	Disallow: /


	User-agent: Baiduspider
	Disallow: /
			
5. Web Exploitation

	Directory Traversal - Information
	
	http://10.50.34.125/path/pathdemo.php
	
	../../../../../../../../../../../etc/passwd
	- http://10.50.34.125/path/pathdemo.php?
	- http://10.50.34.125/path/pathdemo.php?myfile
	- http://10.50.34.125/path/pathdemo.php?myfile=
	- http://10.50.34.125/path/pathdemo.php?myfile=../../../../../../../../../../../etc/passwd
	- http://10.50.34.125/path/pathdemo.php?myfile=../../../../../../../../../../../etc/passwd&
	- http://10.50.34.125/path/pathdemo.php?myfile=../../../../../../../../../../../etc/passwd&submit=File+look+up		##also works



	
	
	files to read:
		- /etc/passwd		:	user information ((look for login shells/bash shells!)
		- /etc/group		:	groups that users are in ((look for root|adm|sudo))
		- /etc/hosts		:	shows webservers, dns servers, internal networks, or labelled network information	
		- /etc/resolv.conf	:	shows internal IP networks we can scan for
		- /etc/networks		:	
		
		
	

	
	
	
### NIKTO

nikto v -h 10.50.34.125

	
	

